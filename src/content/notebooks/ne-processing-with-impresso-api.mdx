---
title: Named Entity Processing with Impresso Models through the Impresso API
githubUrl: https://github.com/impresso/impresso-datalab-notebooks/blob/main/annotate/NE-processing_ImpressoAPI.ipynb
authors:
  - impresso-team
sha: 44a3c9f14c74807de3722878701d97ed71fa3e05
date: 2024-10-25T14:18:01Z
googleColabUrl: https://colab.research.google.com/github/impresso/impresso-datalab-notebooks/blob/main/annotate/NE-processing_ImpressoAPI.ipynb
links:
  - href: https://github.com/impresso/impresso-datalab-notebooks/blob/main/annotate/NE-processing_ImpressoHF.ipynb
    label: NE-processing_ImpressoHF
  - href: https://github.com/impresso/impresso-datalab-notebooks/blob/main/annotate/NE-processing_ImpressoHF.ipynb
    label: NE-processing_ImpressoHF
  - href: https://github.com/impresso/impresso-datalab-notebooks/blob/main/starter/basics_ImpressoAPI.ipynb
    label: basics_ImpressoAPI
seealso:
  - ne-processing-with-impresso-hf
---

{/* cell:0 cell_type:markdown */}

## What is this notebook about?

This notebook is similar to the [NE-processing_ImpressoHF](https://github.com/impresso/impresso-datalab-notebooks/blob/main/annotate/NE-processing_ImpressoHF.ipynb) one, except that instead of loading the model from Hugging Face and executing them locally (or on Colab), here we use the annotation functionalities provided by the Impresso API, using the Impresso Python Library. Behind the scene the same models are used.

For more information on the models, please refer to the [NE-processing_ImpressoHF](https://github.com/impresso/impresso-datalab-notebooks/blob/main/annotate/NE-processing_ImpressoHF.ipynb) notebook (we advised starting with it).

For an introduction to the Impresso Python Library, please refer to the [basics_ImpressoAPI](https://github.com/impresso/impresso-datalab-notebooks/blob/main/starter/basics_ImpressoAPI.ipynb).

## What will you learn in this notebook?

By the end of this notebook, you will know how to call the NER and EL Impresso annotation services through the Impresso API, using the Impresso Python Library

{/* cell:1 cell_type:code */}

```python
!pip install --upgrade --force-reinstall impresso
from impresso import version
print(version)
```

{/* cell:2 cell_type:code */}

```python
from impresso import connect
impresso_session = connect()
```

{/* cell:3 cell_type:markdown */}

## Named entity recognition

{/* cell:4 cell_type:code */}

```python
text = """
Hugging Face will offer the product through Amazon and Google's cloud computing services for $1 per hour and on Digital Ocean, a specialty cloud computing company. Companies will also be able to download the Hugging Face offering to run in their own data centers.
"""

result = impresso_session.tools.ner(
    text=text
)

result.df.tail(10)
```

{/* cell:5 cell_type:markdown */}

## Named entity linking

{/* cell:6 cell_type:code */}

```python
text = """
Hugging Face will offer the product through [START] Amazon [END] and Google's cloud computing services for $1 per hour and on Digital Ocean, a specialty cloud computing company. Companies will also be able to download the Hugging Face offering to run in their own data centers.
"""
result = impresso_session.tools.nel(
    text=text
)
result
```

{/* cell:7 cell_type:code */}

```python
text = """
 Hugging Face proposera le produit via les services de cloud computing d'[START] Amazon [END] et de Google pour 1 dollar par heure, ainsi que sur Digital Ocean, une entreprise spécialisée dans le cloud computing. Les entreprises pourront également télécharger l'offre de Hugging Face pour l'exécuter dans leurs propres centres de données.
 """
result = impresso_session.tools.nel(
     text=text
)
result.df
```

{/* cell:8 cell_type:markdown */}

## Named entity processing

{/* cell:9 cell_type:code */}

```python
text = """
Hugging Face will offer the product through Amazon and Google's cloud computing services for $1 per hour and on Digital Ocean, a specialty cloud computing company. Companies will also be able to download the Hugging Face offering to run in their own data centers.
"""
result = impresso_session.tools.ner_nel(
    text=text
)
result.df
```
