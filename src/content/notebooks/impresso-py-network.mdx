---
title: Exploring Entity Co-occurrence Networks
githubUrl: https://github.com/impresso/impresso-datalab-notebooks/blob/main/explore-vis/entity_network.ipynb
authors:
  - impresso-team
sha: 1478d8fc0a739dcf02f9a9cb35e9c950446135af
date: 2025-02-26T08:28:30Z
langModel: En
googleColabUrl: https://colab.research.google.com/github/impresso/impresso-datalab-notebooks/blob/main/explore-vis/entity_network.ipynb
links:
  - href: https://en.wikipedia.org/wiki/Prague_Spring
    label: Prague Spring
seealso:
  - impresso-py-search
levels:
  coding: beginner
  method: intermediate
---

{/* cell:0 cell_type:markdown */}

<a target="_blank" href="https://colab.research.google.com/github/impresso/impresso-datalab-notebooks/4-impresso-py/network_graph.ipynb">
  <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/>
</a>

{/* cell:1 cell_type:markdown */}
## Install dependencies

{/* cell:2 cell_type:code */}
```python
%pip install -q impresso ipysigma networkx tqdm
```

{/* cell:3 cell_type:markdown */}
## Connect to Impresso

{/* cell:4 cell_type:code */}
```python
from impresso import connect, OR, AND

impresso_session = connect()
```

{/* cell:5 cell_type:markdown */}
## Part 1: Get entities and their co-occurrences

### First, we retrieve all person entities mentioned in all articles that talk about the [Prague Spring](https://en.wikipedia.org/wiki/Prague_Spring).

{/* cell:6 cell_type:code */}
```python
query = OR("Prague Spring", "Prager FrÃ¼hling", "Printemps de Prague")
```

{/* cell:7 cell_type:code */}
```python
persons = impresso_session.search.facet(
  facet="person",
  term=query,
  order_by="-count",
  limit=100
)
persons
```

{/* cell:8 cell_type:markdown */}
### Next, we generate all unique pairs of entities with a mention count higher than `n`.
 
First, entities that meet the mention threshold are selected, and then all possible pairs are generated using the `itertools.combinations` function.

The `n` value can be adjusted so that we don't get too many entity combinations. A sweet spot is just under 500 combinations.

{/* cell:9 cell_type:code */}
```python
import itertools

n = 6

df = persons.df
df = df[df["count"] > n]
persons_ids = df.index.tolist()
print(f"Total persons selected: {len(persons_ids)}")

person_ids_combinations = list(itertools.combinations(persons_ids, 2))
print(f"Total combinations: {len(person_ids_combinations)}")
```

{/* cell:10 cell_type:code */}
```python
if len(person_ids_combinations) > 500:
  msg = (
      f"The number of combinations is quite high ({len(person_ids_combinations)}). " +
      "This may put a lot of load on Impresso and your requests may be throttled. " +
      "Try to increase the threshold number of mentions in the cell above which will reduce the number of selected persons. " +
      "You can also disable this error by commenting out this cell, if this number of combinations is expected."
  )
  raise Exception(msg)
```

{/* cell:11 cell_type:markdown */}

### We also retrieve the dates and the number of articles where person entity pairs appear in.

This piece of code gets a facet for every combination of named entities. It is a single call per combination so it may take a while for a large number of combinations.

{/* cell:12 cell_type:code */}
```python
from impresso.util.error import ImpressoError
from time import sleep
from tqdm import tqdm

connections = []

# iterate over entity combinations, and build a query from each pair, faceting on `daterange`
# the `query` variable hold the same value as above, i.e. keyword search for articles
for idx, combo in tqdm(enumerate(person_ids_combinations), total=len(person_ids_combinations)):
  try:
    result = impresso_session.search.facet(
      facet="daterange",
      term=query,
      entity_id=AND(*combo),
      limit=1000
    )
  except ImpressoError as e:
    # a 429 status code means that the request has been throttled
    # we sleep for 2 seconds and try again
    if e.error.status == 429:
      print(f"Sleeping because of {e}")
      sleep(2)

  if result.size > 0:
    df = result.df

    items = list(zip(df.index.tolist(), df['count'].tolist(), [result.url for i in range(len(df))]))
    connections.append((combo, items))
```

{/* cell:13 cell_type:markdown */}
We put all in a dataframe

{/* cell:14 cell_type:code */}
```python
import pandas as pd

connections_denormalised = []
for c in connections:
  nodes, edges = c

  connections_denormalised.extend(
    [[node_a, node_b, ts, count, url] for (node_a, node_b), (ts, count, url) in zip([nodes for i in range(len(edges))], edges)]
  )

connections_df = pd.DataFrame(connections_denormalised, columns=('node_a', 'node_b', 'timestamp', 'count', 'url'))
connections_df
```

{/* cell:15 cell_type:markdown */}
And save the connections to a CSV file that can be visualised independently in Part 2. Provide a name for the file.

{/* cell:16 cell_type:code */}
```python
from tempfile import gettempdir

temp_dir = gettempdir()

connections_csv_filename = input("Enter the filename: ").replace(" ", "_")
connections_csv_filepath = f"{temp_dir}/{connections_csv_filename}.csv"
connections_df.to_csv(connections_csv_filepath)
print(f"File saved in {connections_csv_filepath}")
```

{/* cell:17 cell_type:markdown */}
## Part 2: visualise

{/* cell:18 cell_type:code */}
```python
import pandas as pd

connections_df = pd.read_csv(connections_csv_filepath)
connections_df
```

{/* cell:19 cell_type:markdown */}
Group connections counting number of mentions and preserve the URL.

{/* cell:20 cell_type:code */}
```python
grouped_connections_df = connections_df.groupby(['node_a', 'node_b']) \
    .agg({'timestamp': lambda x: ', '.join(list(x)), 'count': 'sum', 'url': lambda x: list(set(x))[0]}) \
    .reset_index()
grouped_connections_df
```

{/* cell:21 cell_type:code */}
```python
import networkx as nx

G = nx.from_pandas_edgelist(
    grouped_connections_df,
    source='node_a',
    target='node_b',
    edge_attr=['count', 'url'],
    create_using=nx.MultiGraph()
)
for i in sorted(G.nodes()):
    G.nodes[i]['url'] = f"https://impresso-project.ch/app/entities/{i}"
G.nodes
```

{/* cell:22 cell_type:markdown */}
Save the file so that it could be downloaded and used elsewhere.

{/* cell:23 cell_type:code */}
```python
from tempfile import gettempdir

temp_dir = gettempdir()

gefx_filename = input("Enter the gefx filename: ").replace(" ", "_")
gefx_filepath = f"{temp_dir}/{gefx_filename}.gefx"

nx.write_gexf(G, gefx_filepath)

print(f"File saved in {gefx_filepath}")
```

{/* cell:24 cell_type:markdown */}
If running in Colab - activate custom widgets to allow `ipysigma` to render the graph.

{/* cell:25 cell_type:code */}
```python
try:
    from google.colab import output
    output.enable_custom_widget_manager()
except:
    pass
```

{/* cell:26 cell_type:markdown */}
Render the graph.

{/* cell:27 cell_type:code */}
```python
import ipywidgets

node_size_widget = ipywidgets.Dropdown(
    options=['Degree', 'Betweenness', 'Eigenvector', 'Closeness'],
    value='Degree',
    disabled=False,
    layout={'width': 'max-content'}
)
ipywidgets.Box(
    [
        ipywidgets.Label(value='What should represent the size of the nodes:'), 
        node_size_widget
    ]
)

```

{/* cell:28 cell_type:markdown */}
Refresh the next cell after changing the value above.

{/* cell:29 cell_type:code */}
```python
import networkx as nx
from ipysigma import Sigma

# Importing a gexf graph
g = nx.read_gexf(gefx_filepath)

node_size = None
# Read node size method
match node_size_widget.value:
    case 'Degree':
        node_size = g.degree
    case 'Betweenness':
        node_size = nx.betweenness_centrality(g)
    case 'Eigenvector':
        node_size = nx.eigenvector_centrality(g)
    case 'Closeness':
        node_size = nx.closeness_centrality(g)
    case _:
        node_size = g.degree

print(f"Node size method: {node_size_widget.value}.")
print("See the following link for more information about centrality measures: https://networkx.org/documentation/stable/reference/algorithms/centrality.html")

# Displaying the graph with a size mapped on degree and
# a color mapped on a categorical attribute of the nodes
Sigma(g, node_size=node_size, edge_size='count', clickable_edges=True, )
```
